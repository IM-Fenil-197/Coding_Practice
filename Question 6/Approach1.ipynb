{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVKPcrnfET5v",
        "outputId": "bbe3be86-0f84-4cd6-a82c-5b80bfa0bd91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install langchain\n",
        "!pip3 install llama_index\n",
        "!pip3 install openai\n",
        "!pip3 install transformers\n",
        "!pip3 install torch\n",
        "!pip3 install sentence_transformers\n",
        "!pip3 install pinecone-client\n",
        "!pip3 install unstructured\n",
        "!pip3 install openai\n",
        "!pip3 install chromadb\n",
        "! pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n",
        "! pip install pydantic==1.10.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nYKp-Xw43Jx",
        "outputId": "b7fac68d-7d43-4929-a221-3769bcde1c63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.245)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.18)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.15)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.8)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.7.13)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.13)\n",
            "Requirement already satisfied: langchain>=0.0.218 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.0.245)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.27.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.26.16)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.6)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (4.0.2)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (0.0.15)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (1.10.8)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama_index) (2.31.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (3.20.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama_index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama_index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama_index) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama_index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama_index) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama_index) (2023.5.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.5.7)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.3)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured) (20221105)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.65.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (1.22.4)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (41.0.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx->unstructured) (3.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.5.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.8)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.99.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.2.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (1.26.16)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
            "Requirement already satisfied: typing-inspect==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: typing_extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect==0.8.0) (1.0.0)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.10/dist-packages (1.10.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNKvYoUD0gko",
        "outputId": "f96a4c35-afcb-40e5-8149-37b1cbea9e47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR-OPEN_API_KEY'"
      ],
      "metadata": {
        "id": "QC8erOXY4xCW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain,VectorDBQA, VectorDBQAWithSourcesChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "2yEkDkU85XtY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = UnstructuredFileLoader(\n",
        "  '/content/Family_Care_by_W.W.Jacobs.pdf',\n",
        "  mode='paged'\n",
        ")\n",
        "large_doc = documents.load()"
      ],
      "metadata": {
        "id": "ZWjNQRHC6Su5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2faa41f8-b977-41a6-b686-f4f958ae4cbb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading taggers: Package 'taggers' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Error loading tokenizers: Package 'tokenizers' not found\n",
            "[nltk_data]     in index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=25)\n",
        "texts = text_splitter.split_documents(large_doc)"
      ],
      "metadata": {
        "id": "lLmlQAKk6m4J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[16].page_content"
      ],
      "metadata": {
        "id": "TdMlklG7W8O4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "adabee4b-d933-4536-f3b1-1ef6a0a60341"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"I shall ask her,\" said Mr. Barrett, doggedly. \"I was going to wait a bit longer, but if there\\'s any chance of her wrecking her prospects for life by marrying that tailor\\'s dummy it\\'s my duty to risk itfor her sake. I\\'ve seen him talking to her twice myself, but I never thought he\\'d dream of such a thing.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "docsearch = FAISS.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "wsSC90eU_CgJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
        "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)"
      ],
      "metadata": {
        "id": "TjrPybo69ECw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6efdde0-1365-4ae8-cdcd-5a42c6d3aecd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:187: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:782: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py:245: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt1 = \"\"\"\n",
        "You are analyzer of PDF file and you have to give answer based on data you have available\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Mb-8ybsxFgvc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"\"\"\n",
        "who is author of book?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hxTeU-ZcT8uf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = qa({\"query\": query1, \"prompt\": initial_prompt1})"
      ],
      "metadata": {
        "id": "DPcDX6sJUEDn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result1['result'])"
      ],
      "metadata": {
        "id": "LFnaBiaQUPjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926ca11f-ea2b-483b-9c2d-302a1dc06a6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The author of the book is W. W. Jacobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"\"\"\n",
        "What are different characters are there described into books?\n",
        "   \"\"\"\n",
        "result2 = qa({\"query\": query2, \"prompt\": initial_prompt1})"
      ],
      "metadata": {
        "id": "9D4d_N6KIKFY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result2['result'])"
      ],
      "metadata": {
        "id": "gmgo2n82JYsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1081488-3464-411e-d779-6093073d2dcd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The different characters described in the book are Mr. Barrett, Miss Lindsay, Charlotte (Mr. Barrett's sister-in-law), Jernshaw, and Louisa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECTORDBAWITHSOurceschain\n"
      ],
      "metadata": {
        "id": "iSh9CohUe_Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = VectorDBQAWithSourcesChain.from_llm(\n",
        "  llm=ChatOpenAI(model='gpt-3.5-turbo-16k',temperature=0),\n",
        "  vectorstore=docsearch, return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "8OTpx3fnJgFi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"\"\"\n",
        "What is the main concern of Mr. Barrett in this passage?\n",
        "   \"\"\"\n",
        "result3 = chain2({\"question\": query3})"
      ],
      "metadata": {
        "id": "_vyKxX19Rb56"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result3"
      ],
      "metadata": {
        "id": "amIRFQdERgdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadded2a-ccc0-417b-8710-60d74568e4d0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '\\nWhat is the main concern of Mr. Barrett in this passage?\\n   ',\n",
              " 'answer': \"The main concern of Mr. Barrett in this passage is his matrimonial complications and the potential negative impact it may have on his daughter's prospects in life if she were to marry someone he disapproves of.\\n\",\n",
              " 'sources': '/content/Family_Care_by_W.W.Jacobs.pdf',\n",
              " 'source_documents': [Document(page_content='\"I have no doubt it is much the best thing for the children to remain with their mother,\" she said, rising.\\n\\n\"Much the best,\" agreed Mr. Barrett. \"Whatever she is like,\" continued the old lady. \"Are you ready, Louisa?\"\\n\\nMr. Barrett followed them to the door, and then, returning to the room, watched, with glad eyes, their progress up the street.\\n\\n\"Wonder whether she\\'ll keep it to herself?\" he muttered.\\n\\nHis doubts were set at rest next day. All Ramsbury knew by then of his matrimonial complications, and seemed anxious to talk about them; complications which tended to increase until Mr. Barrett wrote out a list of his children\\'s names and ages and learnt it off by heart.', metadata={'source': '/content/Family_Care_by_W.W.Jacobs.pdf', 'coordinates': {'points': ((72.0, 667.10236), (72.0, 699.82236), (543.2378400000001, 699.82236), (543.2378400000001, 667.10236)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'filename': 'Family_Care_by_W.W.Jacobs.pdf', 'file_directory': '/content', 'date': '2023-07-27T19:23:25', 'filetype': 'application/pdf', 'page_number': 6}),\n",
              "  Document(page_content='Mr. Barrett nodded. \"Can\\'t grumble,\" he said modestly. \"I\\'ve got enough to live on. Melbourne\\'s all right, but I thought I\\'d come home for the evening of my life.\"\\n\\n\"Evening!\" repeated his friend. \"Forty-three,\" said Mr. Barrett, gravely. \"I\\'m getting on.\"\\n\\n\"You haven\\'t changed much,\" said the grocer, passing his hand through his spare grey whiskers. \"Wait till you have a wife and seven youngsters. Why, boots alone\"\\n\\nMr. Barrett uttered a groan intended for sympathy. \"Perhaps you could help me with the furnishing,\" he said, slowly. \"I\\'ve never had a place of my own before, and I don\\'t know much about it.\"\\n\\n\"Anything I can do,\" said his friend. \"Better not get much yet; you might marry, and my taste mightn\\'t be hers.\"', metadata={'source': '/content/Family_Care_by_W.W.Jacobs.pdf', 'coordinates': {'points': ((72.0, 669.14236), (72.0, 701.86236), (543.1259999999999, 701.86236), (543.1259999999999, 669.14236)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'filename': 'Family_Care_by_W.W.Jacobs.pdf', 'file_directory': '/content', 'date': '2023-07-27T19:23:25', 'filetype': 'application/pdf', 'page_number': 2}),\n",
              "  Document(page_content='\"Struck with her?\" repeated his friend, sharply. \"I\\'m surprised at you. You\\'ve no business to think of such things.\"\\n\\n\"Why not?\" demanded Mr. Barrett, in tones that were sharper still.\\n\\n\"Why not?\" repeated the other. \"Have you forgotten your wife and children?\"', metadata={'source': '/content/Family_Care_by_W.W.Jacobs.pdf', 'coordinates': {'points': ((72.0, 667.10236), (72.0, 699.82236), (543.2378400000001, 699.82236), (543.2378400000001, 667.10236)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'filename': 'Family_Care_by_W.W.Jacobs.pdf', 'file_directory': '/content', 'date': '2023-07-27T19:23:25', 'filetype': 'application/pdf', 'page_number': 6}),\n",
              "  Document(page_content='\"I shall ask her,\" said Mr. Barrett, doggedly. \"I was going to wait a bit longer, but if there\\'s any chance of her wrecking her prospects for life by marrying that tailor\\'s dummy it\\'s my duty to risk itfor her sake. I\\'ve seen him talking to her twice myself, but I never thought he\\'d dream of such a thing.\"', metadata={'source': '/content/Family_Care_by_W.W.Jacobs.pdf', 'coordinates': {'points': ((72.0, 617.54236), (72.0, 706.60236), (543.47566, 706.60236), (543.47566, 617.54236)), 'system': 'PixelSpace', 'layout_width': 612, 'layout_height': 792}, 'filename': 'Family_Care_by_W.W.Jacobs.pdf', 'file_directory': '/content', 'date': '2023-07-27T19:23:25', 'filetype': 'application/pdf', 'page_number': 8})]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}